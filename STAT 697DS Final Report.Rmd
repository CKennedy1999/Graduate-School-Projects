---
title: "STAT 697DS Final Report"
author: "Connor Kennedy"
date: "5/2/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'pdf')
op = function(x, d=2) sprintf(paste0("%1.",d,"f"), x)
```

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(Lahman)
library(GGally)
library(leaps)
library(glmnet)
library(pls)
library(boot)
library(gam)
library(MASS)
library(randomForest)
library(gbm)
library(caret)
```

```{r}
#Load allstar table for a variable later
AS <- AllstarFull %>%
  dplyr::select(-gameID, -teamID, -lgID, -gameNum, -GP, -startingPos) %>%
  mutate(AS = 1)

#Load batting table
#Many years since we will be removing rows later
Bat <- Batting %>%
  filter(yearID > 2013)

#Merge dataframes and binary allstar variable
Combo <- merge(Bat, AS, by = c("playerID", "yearID"), all.x = TRUE) %>%
  mutate(AS = as.factor(ifelse(is.na(AS), 0, AS)),
         AL = ifelse(lgID == 'AL', 1, 0))
```

## Part 1

Make sure it should be written in an academic article format, i.e. write the 
full description and explanation rather than using bullet points and summary. 
(Try to avoid starting sentences starting with “I …”, i. g. “I want to do this 
and that.”, “I think…”) The report should include:

### i. Title.

**A Data Driven Approach to Fantasy Roster Building and MLB All-star Selections** 

### ii. Motivation and interest.

The increase in data availability for sports and legalization of sports betting
has prompted many sports fans and statisticians to model many player outcomes.
MLB players can receive larger contracts or bonuses if they are selected to the
annual all-star team. Players can work on a particular part of their game not
only to help their team, but secure more guaranteed money each season that they
play. Fantasy sports also have exploded with the availability of these 
statistics online at a moments notice. There is quite a bit of money to be made
if someone is able to predict a player's future outcomes. Teams have 
incorporated statistics into their own player scouting to find a market 
inefficiency on undervalued players. Most famously the early 2000s Oakland A's
were able to remain competitive while having one of the lowest payrolls in the
league.

### iii. A sample piece of your data set to show what are included.

```{r}
head(Combo)
```

### iv. Data summary (variable names and types)

Include the multi-panel scatter plots and correlation table. All graphs should 
be legible. Describe your findings directly from the data set.

```{r, message=F, warning=F}
ggpairs(Combo, columns = 6:11, 
        lower = list(continuous = wrap("points", color="red", alpha=0.5), 
                     combo = wrap("box", color="orange", alpha=0.3), 
                     discrete = wrap("facetbar", color="yellow", alpha=0.3)), 
        diag = list(continuous = wrap("densityDiag", color="blue", alpha=0.5)))

ggpairs(Combo, columns = 12:17, 
        lower = list(continuous = wrap("points", color="red", alpha=0.5), 
                     combo = wrap("box", color="orange", alpha=0.3), 
                     discrete = wrap("facetbar", color="yellow", alpha=0.3)), 
        diag = list(continuous = wrap("densityDiag", color="blue", alpha=0.5)))

ggpairs(Combo, columns = 18:24, 
        lower = list(continuous = wrap("points", color="red", alpha=0.5), 
                     combo = wrap("box", color="orange", alpha=0.3), 
                     discrete = wrap("facetbar", color="yellow", alpha=0.3)), 
        diag = list(continuous = wrap("densityDiag", color="blue", alpha=0.5)))

ggcorr(data = Combo, label = F)
```

## Part 2

Specify what your goal is. In other words, what and why do you want to predict 
based on the statistical learning techniques. Choose one qualitative response 
and one quantitative response for regression and classification analysis in 
Problems 6 and 7.

```{r, message=F}
#Use Lahman function to grab 'total bases' for fantasy scoring
ESPN <- battingStats(data = Combo, cbind = TRUE, 
                     idvars = c("playerID", "yearID", "stint", "teamID",
                                "lgID")) %>%
  dplyr::select(-c(BA, PA, SlugPct, OBP, OPS, BABIP, stint, teamID, lgID)) %>%
  #Combine stints since players changing teams does not impact fantasy scoring
  group_by(playerID, yearID) %>%
  summarise(G = sum(G), AB = sum(AB), R = sum(R), H = sum(H), X2B = sum(X2B),
            X3B = sum(X3B), HR = sum(HR), RBI = sum(RBI), SB = sum(SB),
            CS = sum(CS), BB = sum(BB), SO = sum(SO), IBB = sum(IBB),
            HBP = sum(HBP), SH = sum(SH), SF = sum(SF), GIDP = sum(GIDP),
            AS = AS, TB = sum(TB)) %>%
  #Calculate fantasy scoring
  mutate(FB = R + TB + RBI + BB - SO + SB)

#Remove duplicate rows
ESPN <- distinct(ESPN)

#Use lead() to grab fantasy scoring from their next season
ESPN_lag <- ESPN %>%
  group_by(playerID) %>%
  mutate(FB_lag = ifelse(yearID < 2019, lead(FB), NA))

#Remove unnecessary rows
ESPN_lag <- na.omit(ESPN_lag)
```

My quantitative variable goal is to predict fantasy baseball scoring using data
from the player's previous season to help people draft their teams.

|    Statistic   | Variable | ESPN Scoring |
| :------------: | :------: | :----------: |
|   Runs Scored  |    R     |       1      |
|   Total Bases  |    TB    |       1      |
| Runs Batted In |    RBI   |       1      |
|      Walks     |    BB    |       1      |
|   Strikeouts   |    SO    |      -1      |
|   Stolen Base  |    SB    |       1      |

My qualitative variable goal is to help predict baseball all-star selections
using only their batting statistics.

## Part 3

Identify the high leverage points? (Remove them unless those are meaningful
points.)

There are a few outliers but none are particularly high leverage. Plots seen in
linear regression under part 6.

## Part 4

Do you need to use log scale or log-log scale? Specify the features if any. 
(When you see your data are highly clustered in one (smaller) side of your axis
and widely scattered in the other side, consider using a log scale for the
variable.

```{r, warning=F}
ESPN2_lag <- ESPN_lag %>%
  mutate(G = log(G + 1), AB = log(AB + 1), R = log(R + 1), H = log(H + 1), 
         RBI = log(RBI + 1), SO = log(SO + 1), TB = log(TB + 1),
         FB = ifelse(FB > 0, log(FB),0), 
         FB_lag = ifelse(FB_lag > 0, log(FB_lag),0))
```

Many "counting" statistics needed a log transformation to help reduce skew.

## Part 5

Missing data points? For missing data points, you can do (you should state what
you used):

```{r}
#Original data
anyNA(ESPN)

#Lagged data
anyNA(ESPN2_lag)
```

There are not any missing data points in the selected data set. I introduced NA
values into the lagged data set to ensure that players without data for the
following season are not given fantasy points from another player. Those rows 
with NA values are then removed since they are not necessary for regression.
None of the following missing data methods are applicable or necessary.

i. If there are only very few out of many data points, you may just remove them.

ii. You can use unsupervised learning to fix them. See Reference #1 at the end.

iii. Using random forest to estimate the missing data points. See Reference #2.

## Part 6

For a quantitative response variable, find the following regression models 
(coefficients) and compare them:

### i. Standard linear model. (Chapter 3)

```{r, warning=F}
set.seed(1)

#Fit a full model (except playerID)
SLM <- lm(FB_lag ~ . - playerID, data = ESPN2_lag)
plot(SLM, which = 4)

train.control <- trainControl(method = "cv", number = 10)

SLM.CV <- train(FB_lag ~ . - playerID, data = ESPN2_lag, method = "lm",
                trControl = train.control)

print(SLM.CV)
summary(SLM.CV)
```

### ii. Best subset selection. (Chapter 6)

```{r, warning=F}
set.seed(1)

BSS.fits <- regsubsets(FB_lag ~ . - playerID, data = ESPN2_lag, nvmax = 18,
                       really.big = T)

summary.table <- data.frame(p=apply(summary(BSS.fits)$which,1,sum),
                            rsq=summary(BSS.fits)$rsq,
                            adjr2=summary(BSS.fits)$adjr2,
                            cp=summary(BSS.fits)$cp,
                            bic=summary(BSS.fits)$bic)
#Check best fitted models & associated criteria
cbind(summary(BSS.fits)$which, summary.table)

BSS <- train(FB_lag ~ G + AB + R + X2B + CS + SO + IBB + SH + FB,
             data=ESPN2_lag, method = "lm", trControl = train.control)
print(BSS)
summary(BSS)
```

### iii. The Lasso. (Chapter 6)

```{r}
set.seed(1)

lasso.x <- model.matrix(FB_lag ~ . - playerID, ESPN2_lag)[, -1]
lasso.y <- ESPN2_lag$FB_lag

lasso.cv.out <- cv.glmnet(lasso.x, lasso.y, alpha = 1, type.measure = "mse")

plot(lasso.cv.out)
lasso.cv.out
```

Lasso with 10-fold CV selects $\lambda$ = 0.0014 with an estimated test MSE
of 1.074.

### iv. Partial Least Squares. (Chapter 6)

```{r}
set.seed(1)

PLS <- plsr(FB_lag ~ . - playerID, data = ESPN2_lag, scale = T,
            validation = "CV")

validationplot(PLS, val.type = "MSEP")

MSEP(PLS)$val[1,1,]

which.min(MSEP(PLS)$val[1,1,])
min(MSEP(PLS)$val[1,1,])
```

Partial least squares regression with 10-fold CV selects 15 components with an
estimated test MSE of 1.072993. There is dimension reduction since there are 21
possible predictors.

### v. Polynomial (find the best polynomial degree.) (Chapter 7)

```{r}
set.seed(1)

Batting.deltas <- rep(NA, 10)
for (i in 1:10) {
Batting.fit <- glm(FB_lag ~ poly(AB, i), data = ESPN2_lag)
Batting.deltas[i] <- cv.glm(ESPN_lag, Batting.fit, K = 10)$delta[1]
}

plot(1:10, Batting.deltas, xlab = "Degree", ylab = "Test MSE", type = "b")

min(Batting.deltas)
which.min(Batting.deltas)

Batting.fit1 <- lm(FB_lag ~ AB, data = ESPN2_lag)
Batting.fit2 <- lm(FB_lag ~ poly(AB, 2), data = ESPN2_lag)
Batting.fit3 <- lm(FB_lag ~ poly(AB, 3), data = ESPN2_lag)
Batting.fit4 <- lm(FB_lag ~ poly(AB, 4), data = ESPN2_lag)
Batting.fit5 <- lm(FB_lag ~ poly(AB, 5), data = ESPN2_lag)
anova(Batting.fit1, Batting.fit2, Batting.fit3, Batting.fit4, Batting.fit5)

Poly <- train(FB_lag ~ AB + AB^2, data=ESPN2_lag, method = "lm",
              trControl = train.control)
print(Poly)
```

For 10-fold CV, d = 1 is the optimal degree for the polynomial since it has the
smallest test MSE. This is not supported when using ANOVA as a quadratic
polynomial  seems most appropriate. These calculations were done when using 
at-bats (AB) as the sole predictor of lagged fantasy points (FB_lag).

### vi. Natural cubic spline (either state the degree of freedom or knots.) (Chapter 7)

```{r, warning=F}
set.seed(1)

NCS <- lm(ESPN2_lag$FB_lag ~ ns(ESPN_lag$AB, df = 5))
summary(NCS)

NCS.CV <- train(FB_lag ~ ns(AB, df = 5), data = ESPN2_lag, 
                method = "lm", trControl = train.control)
print(NCS.CV)
```

The natural spline is fit using 5 degrees of freedom.

### vii. Smoothing spline. (Chapter 7)

```{r, warning=F}
set.seed(1)

Smooth <- smooth.spline(x = ESPN2_lag$AB, y = ESPN2_lag$FB_lag)

mean(resid(Smooth)^2)
```

### viii. Local Regression. (Chapter 7)

```{r}
set.seed(1)

Local <- loess(ESPN2_lag$FB_lag ~ ESPN2_lag$AB)

mean(resid(Local)^2)
```

### ix. Generalized Additive Model. (Chapter 7)

```{r, warning=F, message=F}
set.seed(1)

split = sample(seq_len(nrow(ESPN2_lag)), size = floor(0.8*nrow(ESPN2_lag)))

#80% train
quan_train = ESPN2_lag[split,]

#20% test
quan_test = ESPN2_lag[-split,]

GAM0 <- gam::gam(FB_lag ~ lo(G, span = 0.7) + s(FB, df = 5), data = ESPN2_lag)

GAM1 <- gam::gam(FB_lag ~ lo(G, span = 0.7) + s(FB, df = 5) + AS,
                 data = ESPN2_lag)

GAM2 <- gam::gam(FB_lag ~ lo(G, span = 0.7) + s(FB, df = 5) + factor(yearID),
                 data = ESPN2_lag)

GAM3 <- gam::gam(FB_lag ~ lo(G, span = 0.7) + s(FB, df = 5) + AS + 
                   factor(yearID), data = ESPN2_lag)

anova(GAM0, GAM1, GAM2, GAM3)

GAM.train <- gam::gam(FB_lag ~ lo(G, span = 0.7) + s(FB, df = 5) + 
                        factor(yearID), data = quan_train)

pred.GAM <- predict(GAM.train, newdata = quan_test)

mse <- mean((quan_test$FB_lag - pred.GAM)^2)
mse
```

Use Cross Validation or Validation Set Approach to compare the estimated test
errors for the above regression. (Chapter 5)

| Approach                   | 10-fold CV MSE |
| :------------------------: | :------------: |
| Standard Linear Model      | 1.07291        |
| Best Subset Selection      | 1.07045        |
| The Lasso                  | 1.074          |
| Partial Least Squares      | 1.072993       |
| Polynomial                 | 1.690098       |
| Natural cubic spline       | 1.38531        |
| Smoothing spline           | 1.348502       |
| Local Regression           | 1.390995       |
| Generalized Additive Model | 0.9918142*     |

*GAM was estimated using validation set approach

Overall the simpler models appeared to outperform many more complicated models.
I believe this is because they are more robust and less prone to overfitting.
GAM had a promising outcome, but I was unable to use 10-fold CV so this is
likely too optimistic. I would prefer to use Best Subset Selection to find a
linear model overall.

### Part 7

For a qualitative response variable, compare the following classification
models:

### i. Logistic Regression. (Chapter 4)

```{r, warning=F}
set.seed(1)

ESPN2 <- ESPN_lag %>% ungroup() %>% dplyr::select(-c(playerID, FB, FB_lag))

split = sample(seq_len(nrow(ESPN2)), size = floor(0.8*nrow(ESPN2)))

#80% train
qual_train = ESPN2[split,]

#20% test
qual_test = ESPN2[-split,]
AS_test = ESPN2$AS[-split]

LR <- glm(AS ~ ., data = ESPN2, family = binomial, subset = split)

prob.LR <- predict(LR, qual_test, type = "response")

pred.LR <- rep(0, length(prob.LR))
pred.LR[prob.LR > 0.5] <- 1

#Confusion table
table(pred.LR, AS_test)

#Test error rate
mean(pred.LR != AS_test)
```

### ii. Linear Discriminant Analysis. (Chapter 4)

```{r, warning=F}
set.seed(1)

LDA <- lda(AS ~ ., data = ESPN2, subset = split)

pred.LDA <- predict(LDA, qual_test)

#Confusion table
table(pred.LDA$class, AS_test)

#Test error rate
mean(pred.LDA$class != AS_test)
```

### iii. Quadratic Discriminant Analysis. (Chapter 4)

```{r}
set.seed(1)

QDA <- qda(AS ~ G + AB + R + H + X2B + X3B + HR + RBI + SB + CS + BB + SO + 
             IBB + HBP + SH + SF + GIDP + yearID, data = ESPN2, subset = split)

pred.QDA <- predict(QDA, qual_test)

#Confusion table
table(pred.QDA$class, AS_test)

#Test error rate
mean(pred.QDA$class != AS_test)
```

### iv. Bagging. Visualize the best tree and the importance plot. (Chapter 8)

```{r}
set.seed(1)

BAG.50 <- randomForest(AS ~ ., data = ESPN2, mtry = 19, ntree = 50)
print(BAG.50)

BAG.100 <- randomForest(AS ~ ., data = ESPN2, mtry = 19, ntree = 100)
print(BAG.100)

BAG.500 <- randomForest(AS ~ ., data = ESPN2, mtry = 19, ntree = 500)
print(BAG.500)

BAG.1000 <- randomForest(AS ~ ., data = ESPN2, mtry = 19, ntree = 1000)
print(BAG.1000)
```

```{r}
#Best tree
print(BAG.500)

#Importance plot
varImpPlot(BAG.500)
```

### v. Random Forest. Visualize the best tree and the importance plot. (Chapter 8)

```{r}
RF.50 <- randomForest(AS ~ ., data = ESPN2, ntree = 50, importance = T)
print(RF.50)

RF.100 <- randomForest(AS ~ ., data = ESPN2, ntree = 100, importance = T)
print(RF.100)

RF.500 <- randomForest(AS ~ ., data = ESPN2, ntree = 500, importance = T)
print(RF.500)

RF.1000 <- randomForest(AS ~ ., data = ESPN2, ntree = 1000, importance = T)
print(RF.1000)
```

```{r}
#Best tree
print(RF.1000)

#Importance plot
varImpPlot(RF.1000)
```

### vi. Boosting. Visualize the best tree and the importance plot. (Chapter 8)

```{r, warning=F}
set.seed(1)

BOOST.50 <- gbm(AS ~ ., data = qual_train, distribution = "multinomial",
                n.trees = 50)
BOOST.est.50 <- predict.gbm(object = BOOST.50, newdata = qual_test, 
                            type = "response", n.trees = 50)
labels.50 <- colnames(BOOST.est.50)[apply(BOOST.est.50, 1, which.max)]
BOOST.cm.50 <- confusionMatrix(qual_test$AS, as.factor(labels.50))
print(BOOST.cm.50)

BOOST.100 <- gbm(AS ~ ., data = qual_train, distribution = "multinomial",
                 n.trees = 100)
BOOST.est.100 <- predict.gbm(object = BOOST.100, newdata = qual_test, 
                             type = "response", n.trees = 100)
labels.100 <- colnames(BOOST.est.100)[apply(BOOST.est.100, 1, which.max)]
BOOST.cm.100 <- confusionMatrix(qual_test$AS, as.factor(labels.100))
print(BOOST.cm.100)

BOOST.500 <- gbm(AS ~ ., data = qual_train, distribution = "multinomial",
                 n.trees = 500)
BOOST.est.500 <- predict.gbm(object = BOOST.500, newdata = qual_test, 
                             type = "response", n.trees = 500)
labels.500 <- colnames(BOOST.est.500)[apply(BOOST.est.500, 1, which.max)]
BOOST.cm.500 <- confusionMatrix(qual_test$AS, as.factor(labels.500))
print(BOOST.cm.500)

BOOST.1000 <- gbm(AS ~ ., data = qual_train, distribution = "multinomial",
                  n.trees = 1000)
BOOST.est.1000 <- predict.gbm(object = BOOST.1000, newdata = qual_test, 
                              type = "response", n.trees = 1000)
labels.1000 <- colnames(BOOST.est.1000)[apply(BOOST.est.100, 1, which.max)]
BOOST.cm.1000 <- confusionMatrix(qual_test$AS, as.factor(labels.1000))
print(BOOST.cm.1000)
```

```{r}
#Best tree
print(BOOST.cm.100)

#Importance plot
summary(BOOST.100)
```

For iv, v and vi, calculate the Gini index on each leaf of the final tree to 
examine the purity of the node. Add an importance plot for each classifier.
(Chapter 8)

Use Cross Validation or Validation Set Approach to compare the estimated test
errors for the above classification. (Chapter 5) Find the confusion matrix 
(true/false positive/negative table) for each classification for comparison.
(Chapter 4)

| Approach                        | Estimated Test Error Rate |
| :-----------------------------: | :-----------------------: |
| Logistic Regression             | 0.06495883                |
| Linear Discriminant Analysis    | 0.07410796                |
| Quadratic Discriminant Analysis | 0.1939616                 |
| Bagging                         | 0.0646                    |
| Random Forest                   | 0.0608                    |
| Boosting                        | 0.0668                    |

Random forest with 1000 trees performed best among all of the classification
models. This model is generally robust enough to deal with outliers in the data
so I agree with the test error rate results. I would use random forest when 
predicting MLB all stars.

## Part 8

Summary of finding and conclusion. Add references if there is any.

When predicting future fantasy baseball scoring the simpler models appeared to
outperform many more complicated models. I believe this is because they are more
robust and less prone to overfitting. I would prefer to use Best Subset 
Selection or Lasso to find useful covariates. I believe that domain knowledge is
key so I would like to run the important covariates by people with more
experience than myself.

When predicting all-star selections using only batting statistics random forest
with 1000 trees performed best among all of the classification models. This 
model is generally robust enough to deal with outliers in the data so I agree 
with the test error rate results. Tree based methods tended to outperform all
other methods so I would continue to use bagging or boosting since they had
similar estimated test error rates.

A potential issue with both of my predictions is the national league's use of
the pitcher in the batting order. Half of baseball requires the pitcher to hit
so a they may have poor batting numbers yet still be selected as an all-star.
Their fantasy scoring also only uses their pitching numbers. Overall pitchers
do not play every day or bat very often so the impact on my models will be
minimized, but a dataset that is able to classify players would be useful.

**REFERENCES**

Lewis, M. (2003). Moneyball: The art of winning an unfair game. 
New York: W.W. Norton.

